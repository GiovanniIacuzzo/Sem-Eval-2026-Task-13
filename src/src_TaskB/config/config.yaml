# -----------------------------------------------------------------------------
# COMMON CONFIGURATION
# -----------------------------------------------------------------------------
common:
  data_dir: "data/Task_B_Processed"
  output_dir: "results/results_TaskB"
  checkpoint_dir: "results/results_TaskB/checkpoints"
  log_dir: "results/results_TaskB/logs"  
  seed: 42
  fp16: true
  num_workers: 4  
  learning_rate: 2.0e-5
  warmup_ratio: 0.1
  weight_decay: 0.01
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0
  languages: ["python", "java", "cpp", "c", "cs", "javascript", "php", "ruby", "rust", "go", "typescript", "kotlin", "swift", "shell"]

# -----------------------------------------------------------------------------
# MODE 1: BINARY (Gatekeeper)
# Task: Human (0) vs AI (1)
# -----------------------------------------------------------------------------
binary:
  model_name: "microsoft/codebert-base"
  num_labels: 2
  use_lora: false
  max_length: 512
  batch_size: 16
  gradient_accumulation_steps: 2
  num_epochs: 4
  early_stop_patience: 2
  class_weights: false
  loss_weights:
    w_ce: 1.0
    w_supcon: 0.1
    w_dann: 0.2

# -----------------------------------------------------------------------------
# MODE 2: FAMILIES (Specialist)
# Task: Classify specific AI model (0-9)
# -----------------------------------------------------------------------------
families:
  model_name: "microsoft/unixcoder-base"
  num_labels: 10
  use_lora: true
  lora_r: 64
  lora_alpha: 128
  lora_dropout: 0.05
  target_modules: ["query", "value", "key", "dense"]
  max_length: 384 
  batch_size: 24
  gradient_accumulation_steps: 1
  num_epochs: 15
  early_stop_patience: 4
  class_weights: true
  learning_rate: 3.0e-4
  loss_weights:
    w_ce: 1.0
    w_supcon: 0.8
    w_dann: 0.5
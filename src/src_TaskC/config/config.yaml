# ==========================================
# SemEval 2026 Task 13 - Subtask C Config
# Optimized for NVIDIA T4 (16GB VRAM)
# Strategy: GraphCodeBERT + LoRA (r32) + Focal Loss + K-Fold
# ==========================================

# ---------------------
# Dataset Configuration
# ---------------------
data:
  train_path: "data/Task_C/train.parquet"
  val_path: "data/Task_C/validation.parquet"
  
  # GraphCodeBERT gestisce bene 512.
  max_length: 512
  
  # Bilanciamento
  balance_languages: True
  # 4000 Ã¨ un buon compromesso. 6000 potrebbe essere troppo se hai lingue rare,
  # costringendo il modello a vedere troppi duplicati (oversampling).
  samples_per_lang: 4000 

# ---------------------
# Model Architecture
# ---------------------
model:
  # CAMBIO CRITICO: GraphCodeBERT per la struttura del codice (Data Flow)
  model_name: "microsoft/graphcodebert-base"
  
  num_labels: 4 
  
  use_lora: true 
  
  # Dropout leggermente aumentato per regolarizzare il backbone
  extra_dropout: 0.2 
  
  languages:
    - python
    - java
    - c++
    - c
    - c#
    - javascript
    - typescript
    - go
    - php
    - ruby
    - rust

# ---------------------
# Training Hyperparameters
# ---------------------
training:
  output_dir: "./results_TaskC"
  checkpoint_dir: "./results_TaskC/checkpoints"
  log_dir: "./results_TaskC/logs"
  
  num_epochs: 10
  early_stop_patience: 3
  
  # --- Memory Strategy T4 (Safe Mode) ---
  batch_size: 8
  gradient_accumulation_steps: 8
  
  # --- Learning Rate ---
  learning_rate: 0.0002
  
  evaluation_metric: "f1" 
  
  warmup_ratio: 0.1
  fp16: true
  

  label_smoothing: 0.0

# ---------------------
# Demo Mode
# ---------------------
demo:
  active: false
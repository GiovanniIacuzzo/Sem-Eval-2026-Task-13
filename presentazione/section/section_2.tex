% --- SEZIONE 2: DATA ANALYSIS ---
\section{Analisi dei Dati}

% ==============================================================================
% SUBTASK A
% ==============================================================================
\begin{frame}{Data Distribution: The Training Bias}
    \vspace{-0.2cm}
    \small
    Analizzando il Training Set (500k samples), emerge un chiaro \textbf{sbilanciamento} verso i linguaggi mainstream.
    \vspace{0.2cm}

    \begin{columns}[T] % Allineamento in alto per ordine visivo
        
        % --- COLONNA SINISTRA: GRAFICO ---
        \begin{column}{0.63\textwidth}
            \begin{tcolorbox}[
                enhanced, 
                colback=white, 
                colframe=gray!15, % Bordo grigio chiaro elegante
                drop fuzzy shadow, 
                boxrule=1pt, 
                arc=3pt
            ]
                \centering
                % Immagine: Distribuzione Linguaggi nel Train
                \includegraphics[width=\linewidth, height=5cm, keepaspectratio]{../img/img_TaskA/Train_label_language.png}
            \end{tcolorbox}
            \vspace{0.1cm}
            \centering \tiny \color{gray} \textit{Fig 1. Distribuzione dei linguaggi nel training set.}
        \end{column}
        
        % --- COLONNA DESTRA: ANALISI (Fixed Leggibilità) ---
        \begin{column}{0.35\textwidth}
            
            % TITOLO SEZIONE
            \textbf{\color{Obsidian}\faChartPie \ Composizione}
            \vspace{0.2cm}
            
            % STATISTICA CHIAVE (Evidenziata)
            \begin{tcolorbox}[
                colback=gray!5, 
                frame hidden, 
                left=2pt, right=2pt, top=2pt, bottom=2pt
            ]
                \centering
                \textbf{\color{VividViolet}\Huge 80\%}
                \par
                \scriptsize \textbf{Python}
                \par \tiny (High Resource Languages)
            \end{tcolorbox}
            
            \vspace{0.3cm}
            \pause
            % RISCHIO (Box di Allerta Leggibile)
            \begin{tcolorbox}[
                enhanced,
                title=\textbf{\small \faExclamationTriangle \ The Risk},
                colframe=Obsidian,      % Bordo scuro
                colback=white,          % Sfondo bianco (LEGGIBILE)
                coltitle=white,         % Titolo bianco su bordo scuro
                boxed title style={colback=Obsidian},
                fonttitle=\bfseries,
                fontupper=\scriptsize,  % Testo piccolo ma chiaro
                arc=2pt
            ]
                Il modello rischia il \textbf{"Syntactic Overfitting"}: impara a riconoscere le keyword di Python (`def`, `import`) invece di capire se il codice è generato da un'AI.
            \end{tcolorbox}
            
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{The Shift: Confronto Train vs Test}
    \vspace{-0.2cm}
    \small
    Il Test Set non è solo "più dati". È un cambio di paradigma.
    \vspace{0.2cm}
    
    \begin{columns}[T]
        % TRAIN (RIMPICCIOLITO PER CONFRONTO)
        \begin{column}{0.48\textwidth}
            \centering \scriptsize \textbf{TRAIN (Seen)}
            \begin{tcolorbox}[enhanced, colback=white, colframe=gray!20, boxrule=0.5pt]
                \includegraphics[width=\linewidth, height=3cm, keepaspectratio]{../img/img_TaskA/Train_label_language.png}
            \end{tcolorbox}
        \end{column}
        
        % TEST (HIGHLIGHT)
        \begin{column}{0.48\textwidth}
            \centering \scriptsize \textbf{\color{VividViolet}TEST (Unseen)}
            \begin{tcolorbox}[enhanced, colback=white, colframe=VividViolet, boxrule=1pt, drop fuzzy shadow]
                \includegraphics[width=\linewidth, height=3cm, keepaspectratio]{../img/img_TaskA/Test_label_language.png}
            \end{tcolorbox}
        \end{column}
    \end{columns}
    \pause
    \vspace{0.3cm}
    
    % --- CORREZIONE QUI ---
    % Sostituito colleftrule con borderline west e frame hidden
    \begin{tcolorbox}[
        enhanced,
        colback=gray!5, 
        frame hidden,               % Nasconde il bordo standard
        borderline west={3pt}{0pt}{VividViolet}, % Crea la linea viola a sinistra
        sharp corners,              % Angoli netti per stile "nota"
        left=6pt,                   % Spazio tra la linea e il testo
        right=2pt, top=2pt, bottom=2pt
    ]
        \small
        \textbf{\faExclamationTriangle \ Osservazione:}
        Nel Test set compaiono \textbf{Go, PHP e C\#}. 
        Se il nostro modello si è basato su \textit{keyword} specifiche di Python (es. `def`, `import`), fallirà miseramente qui. Serve astrazione.
    \end{tcolorbox}
\end{frame}

\begin{frame}{Code Properties: Human vs AI Verbosity}
    \vspace{-0.2cm}
    \small
    Esiste una differenza strutturale tra codice Umano e AI? \pause Sì: la \textbf{Lunghezza}.
    \vspace{0.2cm}
    \pause
    \begin{columns}[c]
        % GRAFICO
        \begin{column}{0.6\textwidth}
            \begin{tcolorbox}[enhanced, colback=white, colframe=gray!20, drop fuzzy shadow, boxrule=0.5pt, arc=2pt]
                % Assicurati che l'immagine sia log-scale per vedere bene la differenza
                \includegraphics[width=\linewidth, height=4.5cm, keepaspectratio]{../img/img_TaskA/Train_length_label.png}
            \end{tcolorbox}
        \end{column}
        
        % SPIEGAZIONE
        \begin{column}{0.38\textwidth}
            \textbf{\small \faRulerHorizontal \ Analisi Stilistica}
            \vspace{0.2cm}
            \scriptsize
            \begin{itemize}
                \setlength\itemsep{1.2em} % Spazio tra i punti per leggibilità
                
                \item[\color{CyanGlow}\faRobot] \textbf{AI Code (Verboso):} 
                \\
                I modelli tendono alla \textit{sovrastruttura}: includono spesso commenti esplicativi, gestione errori standard e codice "boilerplate" non richiesto.
                
                \item[\color{Obsidian}\faUser] \textbf{Human Code (Conciso):} 
                \\
                In contesti algoritmici (es. LeetCode), l'umano punta all'essenziale, omettendo commenti e ottimizzando la brevità.
            \end{itemize}
            \pause
            \vspace{0.4cm}
            
            % Insight finale
            \begin{tcolorbox}[colback=CyanGlow!5, colframe=CyanGlow, leftrule=2pt, frame hidden, arc=0pt]
                \centering \tiny 
                \textbf{\faLightbulb \ Insight:} La lunghezza (token count) è un forte segnale predittivo.
            \end{tcolorbox}
        \end{column}
    \end{columns}
\end{frame}

% ==============================================================================
% SUBTASK B
% ==============================================================================
\begin{frame}{Task B: The Imbalance Challenge}
    \vspace{-0.2cm}
    \small
    Il dataset grezzo contiene 31 varianti di modelli. Abbiamo normalizzato le label in \textbf{11 Famiglie}.
    \vspace{0.2cm}
    
    \begin{columns}[T]
        \begin{column}{0.65\textwidth}
            \begin{tcolorbox}[enhanced, colback=white, colframe=gray!20, drop fuzzy shadow, boxrule=0.5pt]
                \includegraphics[width=\linewidth, height=4.5cm, keepaspectratio]{../img/img_TaskB/Train_class_dist.png}
            \end{tcolorbox}
        \end{column}
        
        \begin{column}{0.32\textwidth}
            \begin{tcolorbox}[colback=gray!5, colframe=Obsidian, title=\textbf{Preprocessing}, fonttitle=\bfseries\scriptsize, left=2pt, right=2pt]
                \tiny
                \textbf{Mapping Strategy:}
                \begin{itemize}
                    \item \texttt{llama-2-7b} $\to$ \textbf{LLaMA}
                    \item \texttt{gpt-3.5-turbo} $\to$ \textbf{GPT}
                    \item \texttt{deepseek-coder} $\to$ \textbf{DeepSeek}
                \end{itemize}
            \end{tcolorbox}
            \pause
            \vspace{0.1cm}
            
            \begin{tcolorbox}[colback=VividViolet!10, frame hidden, title=\color{VividViolet}\faBalanceScale\ The Issue, coltitle=VividViolet, fonttitle=\bfseries\scriptsize]
                \tiny
                La classe \textbf{Human} domina (90\%).
                Le classi AI sono rare (<1\%).
            \end{tcolorbox}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Task B: Stylistic Fingerprints}
    \vspace{-0.2cm}
    \small
    Ogni famiglia di modelli ha una "firma" unica? \pause Sì, la \textbf{lunghezza dei token} lo rivela.\pause
    \vspace{0.2cm}

    \begin{columns}[T]
        \begin{column}{0.6\textwidth}
            \begin{tcolorbox}[enhanced, colback=white, colframe=gray!20, drop fuzzy shadow, boxrule=0.5pt]
                \includegraphics[width=\linewidth, height=4.8cm, keepaspectratio]{../img/img_TaskB/Train_token_boxplot.png}
            \end{tcolorbox}
        \end{column}
        
        \begin{column}{0.38\textwidth}
            \textbf{\small \faFingerprint \ Analisi}
            \vspace{0.2cm}
            \scriptsize
            Il grafico mostra la distribuzione dei token per famiglia.
            \vspace{0.3cm}
            
            {\color{CyanGlow}\faPlusCircle} \ \textbf{Verbose Models}
            \par
            \vspace{0.05cm}
            \textbf{GPT \& Claude.} Tendono a spiegare molto, producendo outlier lunghi.
            
            \vspace{0.3cm}
            
            {\color{VividViolet}\faMinusCircle} \ \textbf{Concise Models}
            \par
            \vspace{0.05cm}
            \textbf{LLaMA \& Mistral.} Spesso addestrati per essere diretti o usati per code-completion pura.
            
            \vspace{0.4cm}
            \textit{\tiny Questo pattern aiuta a distinguere GPT da LLaMA anche a parità di correttezza del codice.}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Task B: Model Specialization}
    \vspace{-0.2cm}
    \small
    Esiste una correlazione tra Generatore e Linguaggio? \pause La Heatmap rivela bias specifici.\pause
    \vspace{0.2cm}
    
    \begin{columns}[T]
        \begin{column}{0.55\textwidth}
            \begin{tcolorbox}[enhanced, colback=white, colframe=gray!20, drop fuzzy shadow, boxrule=0.5pt]
                \includegraphics[width=\linewidth, height=4.5cm, keepaspectratio]{../img/img_TaskB/Validation_heatmap_norm.png}
            \end{tcolorbox}
        \end{column}
        
        \begin{column}{0.42\textwidth}
            \textbf{\small \faBraille \ Probability Signature}
            \par\vspace{0.1cm}
            \scriptsize
            Analisi di $P(\text{Language} | \text{Generator})$:
            \vspace{0.3cm}
            
            \begin{itemize}
                \setlength\itemsep{0.8em}
                
                \item \textbf{Mono-Linguaggio (StarCoder):} 
                Un caso estremo. Il \textbf{82\%} del suo codice è Python. Se il sample è C\# o PHP, è quasi certamente \textit{non} StarCoder.
                
                \item \textbf{Enterprise Bias (IBM Granite):} 
                Mostra una preferenza distintiva per \textbf{Java} (0.35), differenziandosi da Llama che preferisce Python (0.45).
                
                \item \textbf{Generalisti (GPT):} 
                Bilanciato tra Java (0.26), Python (0.20) e JS (0.19). Più difficile da attribuire basandosi solo sul linguaggio.
            \end{itemize}
        \end{column}
    \end{columns}
\end{frame}

% ==============================================================================
% SUBTASK C
% ==============================================================================
\begin{frame}{Task C: The Class Imbalance Problem}
    \vspace{-0.2cm}
    \small
    Il Subtask C introduce le "Minority Classes" (Hybrid, Adversarial).
    L'analisi della distribuzione rivela una sfida critica per il training.
    \vspace{0.2cm}

    \begin{columns}[c]
        \begin{column}{0.6\textwidth}
            \begin{tcolorbox}[enhanced, colback=white, colframe=gray!20, drop fuzzy shadow, boxrule=0.5pt]
                \includegraphics[width=\linewidth, height=4.5cm, keepaspectratio]{../img/img_TaskC/Train_target_dist.png}
            \end{tcolorbox}
        \end{column}
        
        \begin{column}{0.38\textwidth}
            \textbf{\small \faChartBar \ Class Breakdown}
            \vspace{0.2cm}
            \scriptsize
            
            \begin{itemize}
                \setlength\itemsep{0.8em}
                \item \textbf{Dominanti (Classes 0-1):} Human e Machine pure coprono la maggioranza del dataset.
                \item \textbf{Rare (Classes 2-3):} Hybrid e Adversarial sono meno frequenti.
            \end{itemize}
            \pause
            \vspace{0.3cm}
            
            \begin{tcolorbox}[colback=VividViolet!10, frame hidden, left=2pt, right=2pt]
                \centering \tiny 
                \textbf{\faTools \ Mitigation Strategy:}
                \par
                Implementazione di \textbf{Class Weights} nella Cross-Entropy Loss per penalizzare gli errori sulle classi rare.
            \end{tcolorbox}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Task C: The Context Window Risk}
    \vspace{-0.2cm}
    \small
    Per rilevare codice Hybrid, il modello deve vedere l'intero snippet.
    L'analisi della lunghezza evidenzia il rischio di troncamento.
    \vspace{0.2cm}

    \begin{columns}[T]
        \begin{column}{0.6\textwidth}
            \begin{tcolorbox}[enhanced, colback=white, colframe=gray!20, drop fuzzy shadow]
                \includegraphics[width=\linewidth, height=4.5cm, keepaspectratio]{../img/img_TaskC/Validation_length_dist.png}
            \end{tcolorbox}
        \end{column}
        
        \begin{column}{0.38\textwidth}
            \textbf{\small \faRulerCombined \ Architectural Constraint}
            \vspace{0.1cm}
            \scriptsize
            Molti Transformer (es. CodeBERT) hanno un limite di 512 token.
            \vspace{0.2cm}
            \pause
            \begin{tcolorbox}[colback=gray!5, colframe=Obsidian, title=\textbf{Analysis}, fonttitle=\bfseries\tiny, left=2pt]
                \tiny
                Se un file Hybrid ha la parte AI alla riga 100 (token 800+), un modello standard la taglierà via, predicendo erroneamente "Human".
            \end{tcolorbox}
            
            \vspace{0.2cm}
            \textbf{\faCheck \ Decisione:} Utilizzare modelli Long-Context o strategie di \textit{Sliding Window}.
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Task C [Test]: Consistency Check}
    \vspace{-0.2cm}
    \small
    Verifica finale sul Sample Test Set per garantire coerenza distributiva prima della sottomissione.
    \vspace{0.2cm}

    \begin{columns}[T]
        \begin{column}{0.48\textwidth}
            \centering \scriptsize \textbf{\faLanguage \ Test Languages}
            \begin{tcolorbox}[enhanced, colback=white, colframe=gray!20, boxrule=0.5pt, height=3.5cm, valign=center]
                \includegraphics[width=\linewidth, height=3.0cm, keepaspectratio]{../img/img_TaskC/Test_Sample_languages.png}
            \end{tcolorbox}
        \end{column}
        
        \begin{column}{0.48\textwidth}
            \centering \scriptsize \textbf{\faBullseye \ Target Distribution}
            \begin{tcolorbox}[enhanced, colback=white, colframe=gray!20, boxrule=0.5pt, height=3.5cm, valign=center]
                \includegraphics[width=\linewidth, height=3.0cm, keepaspectratio]{../img/img_TaskC/Test_Sample_target_dist.png}
            \end{tcolorbox}
        \end{column}
    \end{columns}
    
    \vspace{0.2cm}
    \centering
    \scriptsize \textit{Conferma: Il Test set mantiene la frammentazione linguistica e lo sbilanciamento delle classi visto nel Train.}
\end{frame}